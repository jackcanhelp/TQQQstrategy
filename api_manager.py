"""
API Key & Model Manager
========================
ç®¡ç†å¤šçµ„ Gemini API Key + å¤šæ¨¡å‹è‡ªå‹•åˆ‡æ›ï¼Œæœ€å¤§åŒ–å…è²»é…é¡ä½¿ç”¨ã€‚
ç•¶ Gemini é…é¡ç”¨å®Œæ™‚ï¼Œè‡ªå‹•åˆ‡æ›åˆ° GitHub Models APIã€‚

Features:
- 10 çµ„ Gemini API Key è¼ªæ›
- å¤šæ¨¡å‹ failover (gemini-2.5-flash-lite â†’ gemini-2.0-flash â†’ ...)
- GitHub Models ä½œç‚ºçµ‚æ¥µå‚™ç”¨ (GPT-4o, DeepSeek, Llama)
- æ™ºèƒ½ç­‰å¾…èˆ‡é‡è©¦
"""

import os
import time
import re
from datetime import datetime, timedelta
from typing import Optional, List, Tuple, Dict
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()

# GitHub Models é…ç½®
GITHUB_MODELS_ENDPOINT = "https://models.github.ai/inference"
GITHUB_MODELS = [
    "openai/gpt-4.1",
    "openai/gpt-4o",
    "deepseek/DeepSeek-V3-0324",
    "meta/Llama-4-Scout-17B-16E-Instruct",
]


# æ¨¡å‹å„ªå…ˆé †åºï¼ˆå¾å¿«åˆ°æ…¢ï¼Œç”¨å¥½ç”¨æ»¿å…è²»é¡åº¦ï¼‰
MODELS = [
    "gemini-2.5-flash-lite",  # æœ€å¿«ï¼Œè¼•é‡
    "gemini-2.0-flash-lite",  # å¿«ï¼Œè¼•é‡
    "gemini-2.5-flash",       # å¿«
    "gemini-2.0-flash",       # å¿«
    "gemini-1.5-flash",       # å¿«ï¼ˆæœ‰å°±ç”¨ï¼Œæ²’æœ‰å°±è·³éï¼‰
    "gemini-2.5-pro",         # è¼ƒæ…¢ä½†æ›´å¼·
    "gemini-exp-1206",        # å¯¦é©—ç‰ˆ
]


class APIKeyManager:
    """
    ç®¡ç†å¤šçµ„ API Key + å¤šæ¨¡å‹ï¼Œé‡åˆ°é…é¡é™åˆ¶è‡ªå‹•åˆ‡æ›ã€‚

    ç­–ç•¥ï¼š
    1. å…ˆå˜—è©¦ç•¶å‰ Key + ç•¶å‰ Model
    2. å¦‚æœ 429 éŒ¯èª¤ â†’ åˆ‡æ›åˆ°ä¸‹ä¸€å€‹ Key
    3. å¦‚æœæ‰€æœ‰ Key å°ç•¶å‰ Model éƒ½å¤±æ•— â†’ åˆ‡æ›åˆ°ä¸‹ä¸€å€‹ Model
    4. å¦‚æœæ‰€æœ‰çµ„åˆéƒ½å¤±æ•— â†’ ç­‰å¾…å¾Œé‡è©¦
    """

    def __init__(self, keys: List[str] = None, models: List[str] = None):
        """
        åˆå§‹åŒ– API Key + Model ç®¡ç†å™¨ã€‚
        """
        if keys is None:
            keys = self._load_keys_from_env()

        self.keys = [k for k in keys if k]
        self.models = models or MODELS.copy()

        self.current_key_index = 0
        self.current_model_index = 0

        # è¿½è¹¤æ¯å€‹ (key, model) çµ„åˆçš„ç‹€æ…‹
        self.combo_status: Dict[Tuple[str, str], Dict] = {}
        for key in self.keys:
            for model in self.models:
                self.combo_status[(key, model)] = {
                    'blocked_until': None,
                    'fail_count': 0,
                    'success_count': 0
                }

        # å…¨å±€çµ±è¨ˆ
        self.total_requests = 0
        self.total_successes = 0
        self.model_switches = 0
        self.key_switches = 0

        print(f"ğŸ”‘ API Manager åˆå§‹åŒ–:")
        print(f"   {len(self.keys)} çµ„ API Key")
        print(f"   {len(self.models)} å€‹æ¨¡å‹: {', '.join(self.models)}")
        print(f"   ç¸½å…± {len(self.keys) * len(self.models)} ç¨®çµ„åˆå¯ç”¨")

        self._configure_current()

    def _load_keys_from_env(self) -> List[str]:
        """å¾ç’°å¢ƒè®Šæ•¸è®€å–æ‰€æœ‰ API Keyã€‚"""
        keys = []

        main_key = os.getenv('GOOGLE_API_KEY')
        if main_key:
            keys.append(main_key)

        for i in range(1, 20):
            key = os.getenv(f'GOOGLE_API_KEY_{i}')
            if key:
                keys.append(key)

        return keys

    def _configure_current(self):
        """è¨­å®šç•¶å‰çš„ Keyã€‚"""
        if not self.keys:
            raise ValueError("æ²’æœ‰å¯ç”¨çš„ API Keyï¼")

        current_key = self.keys[self.current_key_index]
        genai.configure(api_key=current_key)

    @property
    def current_key(self) -> str:
        return self.keys[self.current_key_index]

    @property
    def current_model(self) -> str:
        return self.models[self.current_model_index]

    def _rotate_key(self) -> bool:
        """
        åˆ‡æ›åˆ°ä¸‹ä¸€å€‹ Keyã€‚

        Returns:
            True å¦‚æœæˆåŠŸåˆ‡æ›ï¼ŒFalse å¦‚æœå·²ç¶“è¼ªæ›ä¸€åœˆ
        """
        old_index = self.current_key_index
        self.current_key_index = (self.current_key_index + 1) % len(self.keys)
        self.key_switches += 1

        if self.current_key_index == 0:
            # å·²ç¶“è¼ªæ›ä¸€åœˆ
            return False

        self._configure_current()
        print(f"   ğŸ”„ åˆ‡æ› Key: #{old_index + 1} â†’ #{self.current_key_index + 1}")
        return True

    def _rotate_model(self) -> bool:
        """
        åˆ‡æ›åˆ°ä¸‹ä¸€å€‹ Modelã€‚

        Returns:
            True å¦‚æœæˆåŠŸåˆ‡æ›ï¼ŒFalse å¦‚æœå·²ç¶“å˜—è©¦æ‰€æœ‰æ¨¡å‹
        """
        old_model = self.current_model
        self.current_model_index = (self.current_model_index + 1) % len(self.models)
        self.model_switches += 1

        if self.current_model_index == 0:
            # å·²ç¶“å˜—è©¦æ‰€æœ‰æ¨¡å‹
            return False

        print(f"   ğŸ”„ åˆ‡æ›æ¨¡å‹: {old_model} â†’ {self.current_model}")
        return True

    def _get_combo_status(self, key: str = None, model: str = None) -> Dict:
        """å–å¾—æŒ‡å®šçµ„åˆçš„ç‹€æ…‹ã€‚"""
        key = key or self.current_key
        model = model or self.current_model
        return self.combo_status.get((key, model), {})

    def _mark_combo_failed(self, key: str = None, model: str = None, wait_seconds: int = 30):
        """æ¨™è¨˜çµ„åˆå¤±æ•—ã€‚"""
        key = key or self.current_key
        model = model or self.current_model
        combo = (key, model)

        if combo in self.combo_status:
            self.combo_status[combo]['fail_count'] += 1
            self.combo_status[combo]['blocked_until'] = datetime.now() + timedelta(seconds=wait_seconds)

    def _mark_combo_success(self, key: str = None, model: str = None):
        """æ¨™è¨˜çµ„åˆæˆåŠŸã€‚"""
        key = key or self.current_key
        model = model or self.current_model
        combo = (key, model)

        if combo in self.combo_status:
            self.combo_status[combo]['success_count'] += 1
            self.combo_status[combo]['blocked_until'] = None

        self.total_successes += 1

    def _is_combo_available(self, key: str, model: str) -> bool:
        """æª¢æŸ¥çµ„åˆæ˜¯å¦å¯ç”¨ã€‚"""
        status = self.combo_status.get((key, model), {})
        blocked_until = status.get('blocked_until')

        if blocked_until is None:
            return True

        return datetime.now() >= blocked_until

    def _find_available_combo(self) -> Optional[Tuple[str, str]]:
        """
        å°‹æ‰¾ä¸€å€‹å¯ç”¨çš„ (key, model) çµ„åˆã€‚

        Returns:
            (key, model) tuple æˆ– None
        """
        # é¦–å…ˆå˜—è©¦ç•¶å‰æ¨¡å‹çš„æ‰€æœ‰ Key
        for i in range(len(self.keys)):
            key_idx = (self.current_key_index + i) % len(self.keys)
            key = self.keys[key_idx]

            if self._is_combo_available(key, self.current_model):
                self.current_key_index = key_idx
                self._configure_current()
                return (key, self.current_model)

        # ç•¶å‰æ¨¡å‹æ‰€æœ‰ Key éƒ½ä¸å¯ç”¨ï¼Œå˜—è©¦å…¶ä»–æ¨¡å‹
        for m in range(1, len(self.models)):
            model_idx = (self.current_model_index + m) % len(self.models)
            model = self.models[model_idx]

            for i in range(len(self.keys)):
                key_idx = (self.current_key_index + i) % len(self.keys)
                key = self.keys[key_idx]

                if self._is_combo_available(key, model):
                    self.current_key_index = key_idx
                    self.current_model_index = model_idx
                    self._configure_current()
                    print(f"   ğŸ”„ åˆ‡æ›åˆ°: Key #{key_idx + 1} + {model}")
                    return (key, model)

        return None

    def _get_min_wait_time(self) -> int:
        """å–å¾—æœ€çŸ­ç­‰å¾…æ™‚é–“ï¼ˆç§’ï¼‰ã€‚"""
        now = datetime.now()
        min_wait = float('inf')

        for combo, status in self.combo_status.items():
            blocked = status.get('blocked_until')
            if blocked and blocked > now:
                wait = (blocked - now).total_seconds()
                min_wait = min(min_wait, wait)

        return int(min_wait) if min_wait != float('inf') else 0

    def generate_with_failover(
        self,
        prompt: str,
        preferred_model: str = None,
        max_retries: int = None
    ) -> Optional[str]:
        """
        ä½¿ç”¨ Key + Model failover æ©Ÿåˆ¶ç”Ÿæˆå…§å®¹ã€‚

        ç­–ç•¥ï¼š
        1. å˜—è©¦ç•¶å‰ Key + ç•¶å‰ Model
        2. 429 â†’ åˆ‡æ› Key
        3. æ‰€æœ‰ Key å¤±æ•— â†’ åˆ‡æ› Model
        4. æ‰€æœ‰çµ„åˆå¤±æ•— â†’ ç­‰å¾…å¾Œé‡è©¦

        Args:
            prompt: æç¤ºè©
            preferred_model: åå¥½çš„æ¨¡å‹ï¼ˆå¯é¸ï¼‰
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸

        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬ï¼Œå¤±æ•—è¿”å› None
        """
        if preferred_model and preferred_model in self.models:
            self.current_model_index = self.models.index(preferred_model)

        if max_retries is None:
            max_retries = len(self.keys) * len(self.models) * 2

        self.total_requests += 1
        attempts = 0
        keys_tried_for_model = set()

        while attempts < max_retries:
            attempts += 1

            # å°‹æ‰¾å¯ç”¨çµ„åˆ
            combo = self._find_available_combo()

            if combo is None:
                # æ‰€æœ‰çµ„åˆéƒ½è¢«å°é–
                wait_time = self._get_min_wait_time()
                if wait_time > 0:
                    print(f"   â³ æ‰€æœ‰çµ„åˆè¢«é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...")
                    time.sleep(min(wait_time + 1, 60))
                    # é‡ç½®è¿½è¹¤
                    keys_tried_for_model.clear()
                    continue
                else:
                    break

            key, model = combo

            try:
                genai.configure(api_key=key)
                gemini_model = genai.GenerativeModel(model)
                response = gemini_model.generate_content(prompt)

                self._mark_combo_success(key, model)
                return response.text

            except Exception as e:
                error_msg = str(e)

                if '429' in error_msg:
                    # é…é¡è¶…é™
                    wait_time = self._parse_wait_time(error_msg)
                    self._mark_combo_failed(key, model, wait_time)

                    keys_tried_for_model.add(key)

                    # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰ Key å°ç•¶å‰æ¨¡å‹éƒ½å¤±æ•—
                    if len(keys_tried_for_model) >= len(self.keys):
                        print(f"   âš ï¸ {model} æ‰€æœ‰ Key éƒ½è¢«é™åˆ¶ï¼Œåˆ‡æ›æ¨¡å‹...")
                        keys_tried_for_model.clear()
                        if not self._rotate_model():
                            # å·²å˜—è©¦æ‰€æœ‰æ¨¡å‹
                            wait_time = self._get_min_wait_time()
                            if wait_time > 0:
                                print(f"   â³ æ‰€æœ‰æ¨¡å‹è¢«é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...")
                                time.sleep(min(wait_time + 1, 60))
                    else:
                        self._rotate_key()

                elif '404' in error_msg:
                    # æ¨¡å‹ä¸å­˜åœ¨
                    print(f"   âŒ æ¨¡å‹ {model} ä¸å¯ç”¨ï¼Œåˆ‡æ›...")
                    # æ°¸ä¹…å°é–é€™å€‹æ¨¡å‹
                    for k in self.keys:
                        self._mark_combo_failed(k, model, 86400)  # 24 å°æ™‚
                    self._rotate_model()

                elif '503' in error_msg or 'ServiceUnavailable' in error_msg:
                    # æœå‹™æš«æ™‚ä¸å¯ç”¨
                    print(f"   âš ï¸ æœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œåˆ‡æ›...")
                    self._mark_combo_failed(key, model, 10)
                    self._rotate_key()

                else:
                    # å…¶ä»–éŒ¯èª¤
                    print(f"   âš ï¸ API éŒ¯èª¤: {error_msg[:60]}")
                    self._mark_combo_failed(key, model, 5)
                    self._rotate_key()

        print(f"   âŒ Gemini æ‰€æœ‰ {max_retries} æ¬¡å˜—è©¦éƒ½å¤±æ•—")

        # å˜—è©¦ GitHub Models ä½œç‚ºçµ‚æ¥µå‚™ç”¨
        github_result = self._try_github_models(prompt)
        if github_result:
            return github_result

        return None

    def _try_github_models(self, prompt: str) -> Optional[str]:
        """
        ç•¶ Gemini å…¨éƒ¨å¤±æ•—æ™‚ï¼Œå˜—è©¦ GitHub Models APIã€‚
        """
        github_token = os.getenv("GITHUB_TOKEN")
        if not github_token:
            print("   âš ï¸ GITHUB_TOKEN æœªè¨­å®šï¼Œç„¡æ³•ä½¿ç”¨ GitHub Models")
            return None

        try:
            from openai import OpenAI
        except ImportError:
            print("   âš ï¸ openai å¥—ä»¶æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨ GitHub Models")
            return None

        client = OpenAI(
            base_url=GITHUB_MODELS_ENDPOINT,
            api_key=github_token,
        )

        for model in GITHUB_MODELS:
            try:
                print(f"   ğŸ”„ å˜—è©¦ GitHub Models: {model}...")
                response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=2000,
                    temperature=0.7,
                )
                result = response.choices[0].message.content
                print(f"   âœ… GitHub Models ({model}) æˆåŠŸ!")
                self.total_successes += 1
                return result

            except Exception as e:
                error_msg = str(e)
                print(f"   âš ï¸ GitHub {model} å¤±æ•—: {error_msg[:50]}")
                continue

        print("   âŒ GitHub Models ä¹Ÿå…¨éƒ¨å¤±æ•—")
        return None

    def _parse_wait_time(self, error_msg: str) -> int:
        """å¾éŒ¯èª¤è¨Šæ¯è§£æç­‰å¾…æ™‚é–“ã€‚"""
        match = re.search(r'(\d+)\.?\d*\s*s', error_msg.lower())
        if match:
            return int(float(match.group(1))) + 1
        return 30

    def get_status(self) -> str:
        """å–å¾—è©³ç´°ç‹€æ…‹å ±å‘Šã€‚"""
        now = datetime.now()
        lines = [
            "ğŸ”‘ API Manager ç‹€æ…‹:",
            f"   ç¸½è«‹æ±‚: {self.total_requests} | æˆåŠŸ: {self.total_successes}",
            f"   Key åˆ‡æ›: {self.key_switches} | Model åˆ‡æ›: {self.model_switches}",
            "",
            f"   ç•¶å‰: Key #{self.current_key_index + 1} + {self.current_model}",
            ""
        ]

        # çµ±è¨ˆæ¯å€‹æ¨¡å‹çš„å¯ç”¨ Key æ•¸
        for model in self.models:
            available = sum(
                1 for key in self.keys
                if self._is_combo_available(key, model)
            )
            lines.append(f"   {model}: {available}/{len(self.keys)} Keys å¯ç”¨")

        # GitHub Models ç‹€æ…‹
        github_token = os.getenv("GITHUB_TOKEN")
        lines.append("")
        if github_token:
            lines.append(f"   ğŸ™ GitHub Models: âœ… å¯ç”¨ ({len(GITHUB_MODELS)} å€‹æ¨¡å‹ä½œç‚ºå‚™ç”¨)")
        else:
            lines.append("   ğŸ™ GitHub Models: âŒ GITHUB_TOKEN æœªè¨­å®š")

        return "\n".join(lines)

    # ä¿æŒå‘å¾Œå…¼å®¹
    def generate_with_retry(self, prompt: str, model_name: str = None, max_retries: int = None) -> Optional[str]:
        """å‘å¾Œå…¼å®¹çš„ APIã€‚"""
        return self.generate_with_failover(prompt, model_name, max_retries)


# å…¨åŸŸå¯¦ä¾‹
_api_manager = None


def get_api_manager() -> APIKeyManager:
    """å–å¾—å…¨åŸŸ API Manager å¯¦ä¾‹ã€‚"""
    global _api_manager
    if _api_manager is None:
        _api_manager = APIKeyManager()
    return _api_manager
